@article{universal1,
	title={Multilayer feedforward networks are universal approximators},
	author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	journal={Neural networks},
	volume={2},
	number={5},
	pages={359--366},
	year={1989},
	publisher={Elsevier}
}

@article{gnnintro,
	title={A gentle introduction to graph neural networks},
	author={Sanchez-Lengeling, Benjamin and Reif, Emily and Pearce, Adam and Wiltschko, Alexander B},
	journal={Distill},
	volume={6},
	number={9},
	pages={e33},
	year={2021}
}

@misc{chgcnn,
	title={Crystal Hypergraph Convolutional Networks}, 
	author={Alexander J. Heilman and Weiyi Gong and Qimin Yan},
	year={2024},
	eprint={2411.12616},
	archivePrefix={arXiv},
	primaryClass={cond-mat.mtrl-sci},
	url={https://arxiv.org/abs/2411.12616}, 
}

@article{voronoi_alg,
	title={Centroidal Voronoi tessellations: Applications and algorithms},
	author={Du, Qiang and Faber, Vance and Gunzburger, Max},
	journal={SIAM review},
	volume={41},
	number={4},
	pages={637--676},
	year={1999},
	publisher={SIAM}
}

@article{universal2,
	title={Approximation with artificial neural networks},
	author={Cs{\'a}ji, Bal{\'a}zs Csan{\'a}d and others},
	journal={Faculty of Sciences, Etvs Lornd University, Hungary},
	volume={24},
	number={48},
	pages={7},
	year={2001}
}

@article{nn_overview,
	title={An overview of neural network},
	author={Islam, Mohaiminul and Chen, Guorong and Jin, Shangzhu},
	journal={American Journal of Neural Networks and Applications},
	volume={5},
	number={1},
	pages={7--11},
	year={2019},
	publisher={Science Publishing Group}
}
%%Coordination comparison
@Article{coordination_comp,
author={Pan, Hillary
and Ganose, Alex M.
and Horton, Matthew
and Aykol, Muratahan
and Persson, Kristin A.
and Zimmermann, Nils E. R.
and Jain, Anubhav},
title={Benchmarking Coordination Number Prediction Algorithms on Inorganic Crystal Structures},
journal={Inorg. Chem.},
year={2021},
month={02},
day={01},
publisher={American Chemical Society},
volume={60},
number={3},
pages={  1590-1603},
issn={0020-1669},
doi={10.1021/acs.inorgchem.0c02996},
url={https://doi.org/10.1021/acs.inorgchem.0c02996}
}

@article{molgraphcoarse1,
	title={FunQG: molecular representation learning via quotient graphs},
	author={Hajiabolhassan, Hossein and Taheri, Zahra and Hojatnia, Ali and Yeganeh, Yavar Taheri},
	journal={Journal of chemical information and modeling},
	volume={63},
	number={11},
	pages={3275--3287},
	year={2023},
	publisher={ACS Publications}
}

@article{dirl1979,
	title={Clebsch--Gordan coefficients: General theory},
	author={Dirl, R},
	journal={Journal of Mathematical Physics},
	volume={20},
	number={4},
	pages={659--663},
	year={1979},
	publisher={American Institute of Physics}
}

@article{ace_completeness,
	title = {Atomic cluster expansion: Completeness, efficiency and stability},
	journal = {J. Comput, Phys.},
	volume = {454},
	pages = {110946},
	year = {2022},
	issn = {0021-9991},
	doi = {https://doi.org/10.1016/j.jcp.2022.110946},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999122000080},
	author = {Geneviève Dusson and Markus Bachmayr and Gábor Csányi and Ralf Drautz and Simon Etter and Cas {van der Oord} and Christoph Ortner},
	keywords = {Spherical harmonics, Interatomic potentials, Polynomial approximation, Isometry and permutation invariance, Symmetric functions},
	abstract = {The Atomic Cluster Expansion (Drautz (2019) [21]) provides a framework to systematically derive polynomial basis functions for approximating isometry and permutation invariant functions, particularly with an eye to modelling properties of atomistic systems. Our presentation extends the derivation by proposing a precomputation algorithm that yields immediate guarantees that a complete basis is obtained. We provide a fast recursive algorithm for efficient evaluation and illustrate its performance in numerical tests. Finally, we discuss generalisations and open challenges, particularly from a numerical stability perspective, around basis optimisation and parameter estimation, paving the way towards a comprehensive analysis of the convergence to a high-fidelity reference model.}
}

@Article{ace_appplication,
	author={Lysogorskiy, Yury
	and Oord, Cas van der
	and Bochkarev, Anton
	and Menon, Sarath
	and Rinaldi, Matteo
	and Hammerschmidt, Thomas
	and Mrovec, Matous
	and Thompson, Aidan
	and Cs{\'a}nyi, G{\'a}bor
	and Ortner, Christoph
	and Drautz, Ralf},
	title={Performant implementation of the atomic cluster expansion (PACE) and application to copper and silicon},
	journal={npj Comput. Mater.},
	year={2021},
	month={Jun},
	day={28},
	volume={7},
	number={1},
	pages={97},
	abstract={The atomic cluster expansion is a general polynomial expansion of the atomic energy in multi-atom basis functions. Here we implement the atomic cluster expansion in the performant C++ code PACE that is suitable for use in large-scale atomistic simulations. We briefly review the atomic cluster expansion and give detailed expressions for energies and forces as well as efficient algorithms for their evaluation. We demonstrate that the atomic cluster expansion as implemented in PACE shifts a previously established Pareto front for machine learning interatomic potentials toward faster and more accurate calculations. Moreover, general purpose parameterizations are presented for copper and silicon and evaluated in detail. We show that the Cu and Si potentials significantly improve on the best available potentials for highly accurate large-scale atomistic simulations.},
	issn={2057-3960},
	doi={10.1038/s41524-021-00559-9},
	url={https://doi.org/10.1038/s41524-021-00559-9}
}



@article{ace,
	title = {Atomic cluster expansion for accurate and transferable interatomic potentials},
	author = {Drautz, Ralf},
	journal = {Phys. Rev. B},
	volume = {99},
	issue = {1},
	pages = {014104},
	numpages = {15},
	year = {2019},
	month = {Jan},
	publisher = {American Physical Society},
	doi = {10.1103/PhysRevB.99.014104},
	url = {https://link.aps.org/doi/10.1103/PhysRevB.99.014104}
}


@book{Mulas2022,
	author={Mulas, Raffaella
	and Horak, Danijela
	and Jost, J{\"u}rgen},
	editor={Battiston, Federico
	and Petri, Giovanni},
	title={Graphs, Simplicial Complexes and Hypergraphs: Spectral Theory and Topology},
	bookTitle={Higher-Order Systems},
	year={2022},
	publisher={Springer International Publishing},
	address={Cham},
	pages={1-58},
	abstract={In this chapter we discuss the spectral theory of discrete structures such as graphs, simplicial complexes and hypergraphs. We focus, in particular, on the corresponding Laplace operators. We present the theoretical foundations, but we also discuss the motivation to model and study real data with these tools.},
	isbn={978-3-030-91374-8},
	doi={10.1007/978-3-030-91374-8_1},
	url={https://doi.org/10.1007/978-3-030-91374-8_1}
}




%%MatBench Ref
@Article{matbench,
author={Dunn, Alexander
and Wang, Qi
and Ganose, Alex
and Dopp, Daniel
and Jain, Anubhav},
title={Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm},
journal={{npj} Comput. Mater.},
year={2020},
month={09},
day={15},
volume={6},
number={1},
pages={   138},
abstract={We present a benchmark test suite and an automated machine learning procedure for evaluating supervised machine learning (ML) models for predicting properties of inorganic bulk materials. The test suite, Matbench, is a set of 13{\thinspace}ML tasks that range in size from 312 to 132k samples and contain data from 10 density functional theory-derived and experimental sources. Tasks include predicting optical, thermal, electronic, thermodynamic, tensile, and elastic properties given a material's composition and/or crystal structure. The reference algorithm, Automatminer, is a highly-extensible, fully automated ML pipeline for predicting materials properties from materials primitives (such as composition and crystal structure) without user intervention or hyperparameter tuning. We test Automatminer on the Matbench test suite and compare its predictive power with state-of-the-art crystal graph neural networks and a traditional descriptor-based Random Forest model. We find Automatminer achieves the best performance on 8 of 13 tasks in the benchmark. We also show our test suite is capable of exposing predictive advantages of each algorithm---namely, that crystal graph methods appear to outperform traditional machine learning methods given {\textasciitilde}104 or greater data points. We encourage evaluating materials ML algorithms on the Matbench benchmark and comparing them against the latest version of Automatminer.},
issn={2057-3960},
doi={10.1038/s41524-020-00406-3},
url={https://doi.org/10.1038/s41524-020-00406-3}
}



%%coNGN and coGN
@article{congn,
  title={Connectivity optimized nested line graph networks for crystal structures},
  author={Ruff, Robin and Reiser, Patrick and St{\"u}hmer, Jan and Friederich, Pascal},
  journal={Digit. Discov.},
  volume={3},
  number={3},
  pages={   594--601},
  year={2024},
  publisher={Royal Society of Chemistry}
}


%%Materials Project Ref
@article{matproj,
    author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and Persson, Kristin A.},
    title = {Commentary: The Materials Project: A materials genome approach to accelerating materials innovation},
    journal = {APL Mater.},
    volume = {1},
    number = {1},
    pages = {   011002},
    year = {2013},
    month = {07},
    abstract = "{Accelerating the discovery of advanced materials is essential for human welfare and sustainable, clean energy. In this paper, we introduce the Materials Project (www.materialsproject.org), a core program of the Materials Genome Initiative that uses high-throughput computing to uncover the properties of all known inorganic materials. This open dataset can be accessed through multiple channels for both interactive exploration and data mining. The Materials Project also seeks to create open-source platforms for developing robust, sophisticated materials analyses. Future efforts will enable users to perform ‘‘rapid-prototyping’’ of new materials in silico, and provide researchers with new avenues for cost-effective, data-driven materials design.}",
    issn = {2166-532X},
    doi = {10.1063/1.4812323},
    url = {https://doi.org/10.1063/1.4812323},
    eprint = {https://pubs.aip.org/aip/apm/article-pdf/doi/10.1063/1.4812323/13163869/011002\_1\_online.pdf},
}


%%CCE
@article{clease,
  title={CLEASE: a versatile and user-friendly implementation of cluster expansion method},
  author={Chang, Jin Hyun and Kleiven, David and Melander, Marko and Akola, Jaakko and Garcia-Lastra, Juan Maria and Vegge, Tejs},
  journal={J. Phys. Condens. Matter},
  volume={31},
  number={32},
  pages={   325901},
  year={2019},
  publisher={IOP Publishing}
}

@article{cce_gen,
title = {Generalized cluster description of multicomponent systems},
journal = {Physica A Stat. Mech. Appl.},
volume = {128},
number = {1},
pages = {   334-350},
year = {1984},
issn = {0378-4371},
doi = {https://doi.org/10.1016/0378-4371(84)90096-7},
url = {https://www.sciencedirect.com/science/article/pii/0378437184900967},
author = {J.M. Sanchez and F. Ducastelle and D. Gratias}
}

@Article{cce_crys,
author={van de Walle, A.},
title={A complete representation of structure--property relationships in crystals},
journal={Nat. Mater.},
year={2008},
month={06},
day={01},
volume={7},
number={6},
pages={   455-458},
abstract={Cluster expansion has been a particularly successful computational method that has allowed the identification of the relationship between lattice configurations and scalar properties in crystals. A tensorial version of the method that will enable prediction of tensor-valued properties is now introduced. It is validated by predicting anisotropic properties relevant to semiconductor optoelectronic devices.},
issn={1476-4660},
doi={10.1038/nmat2200},
url={https://doi.org/10.1038/nmat2200}
}




%%Maybe interesting, uses graph duals (which are hypergraphs with node representing edges) to learn representations for graph edges
@article{jo2021edge,
  title={Edge Representation Learning with Hypergraphs},
  author={Jo, Jaehyeong and Baek, Jinheon and Lee, Seul and Kim, Dongki and Kang, Minki and Hwang, Sung Ju},
  journal={Adv. Neural Inf. Process. Syst.},
  volume={34},
  pages={   7534--7546},
  year={2021}
}

%%SchNet
@article{schnet,
 author = {Schütt, K. T. and Sauceda, H. E. and Kindermans, P.-J. and Tkatchenko, A. and Müller, K.-R.},
 title = {SchNet – A deep learning architecture for molecules and materials},
 journal = {J. Chem. Phys.},
 volume = {148},
 number = {24},
 pages = {   241722},
 year = {2018},
 month = {03},
 abstract = {Deep learning has led to a paradigm shift in artificial intelligence, including web, text, and image search, speech recognition, as well as bioinformatics, with growing impact in chemical physics. Machine learning, in general, and deep learning, in particular, are ideally suitable for representing quantum-mechanical interactions, enabling us to model nonlinear potential-energy surfaces or enhancing the exploration of chemical compound space. Here we present the deep learning architecture SchNet that is specifically designed to model atomistic systems by making use of continuous-filter convolutional layers. We demonstrate the capabilities of SchNet by accurately predicting a range of properties across chemical space for molecules and materials, where our model learns chemically plausible embeddings of atom types across the periodic table. Finally, we employ SchNet to predict potential-energy surfaces and energy-conserving force fields for molecular dynamics simulations of small molecules and perform an exemplary study on the quantum-mechanical properties of C20-fullerene that would have been infeasible with regular ab initio molecular dynamics.},
 issn = {0021-9606},
 doi = {10.1063/1.5019779},
 url = {https://doi.org/10.1063/1.5019779},
 eprint = {https://pubs.aip.org/aip/jcp/article-pdf/doi/10.1063/1.5019779/16655678/241722\_1\_online.pdf},
 }
 
 
 
 

%%CGCNN
@article{cgcnn,
  title={Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties},
  author={Xie, Tian and Grossman, Jeffrey C},
  journal={{PRL}},
  volume={120},
  number={14},
  pages={   145301},
  year={2018},
  publisher={APS}
}


%%AMDNet
@article{amdnet,
  title={Structure motif--centric learning framework for inorganic crystalline systems},
  author={Banjade, Huta R and Hauri, Sandro and Zhang, Shanshan and Ricci, Francesco and Gong, Weiyi and Hautier, Geoffroy and Vucetic, Slobodan and Yan, Qimin},
  journal={Sci. Adv.},
  volume={7},
  number={17},
  pages={   eabf1754},
  year={2021},
  publisher={American Association for the Advancement of Science}
}

%%ChemGNN@Article
{chemgnn,
author={Chen, Chen
	and Xu, Enze
	and Yang, Defu
	and Yan, Chenggang
	and Wei, Tao
	and Chen, Hanning
	and Wei, Yong
	and Chen, Minghan},
title={Chemical environment adaptive learning for optical band gap prediction of doped graphitic carbon nitride nanosheets},
journal={Neural Comput. Apl.},
year={2024},
month={Dec},
day={12},
volume={37},
abstract={This study presents a new machine learning algorithm, named Chemical Environment Graph Neural Network (ChemGNN), designed to accelerate materials property prediction and advance new materials discovery. Graphitic carbon nitride (g-C3N4) and its doped variants have gained significant interest for their potential as optical materials. Accurate prediction of their band gaps is crucial for practical applications; however, traditional quantum simulation methods are computationally expensive and challenging to explore the vast space of possible doped molecular structures. The proposed ChemGNN leverages the learning ability of current graph neural networks (GNNs) to satisfactorily capture the characteristics of atoms' chemical environment underlying complex molecular structures. Our experimental results demonstrate more than 100{\%} improvement in band gap prediction accuracy over existing GNNs on g-C3N4. Furthermore, the general ChemGNN model can precisely foresee band gaps of various doped g-C3N4 structures, making it a valuable tool for performing high-throughput prediction in materials design and development.},
issn={1433-3058},
doi={10.1007/s00521-024-10775-1},
url={https://doi.org/10.1007/s00521-024-10775-1},
pages = {   3287–3301}
}


%%LSOP Papers
@ARTICLE{orderparam1,
AUTHOR={Zimmermann, Nils E. R. and Horton, Matthew K. and Jain, Anubhav and Haranczyk, Maciej},   
TITLE={Assessing Local Structure Motifs Using Order Parameters for Motif Recognition, Interstitial Identification, and Diffusion Path Characterization},      
JOURNAL={Front. Mater.},      
VOLUME={4},           
YEAR={2017},    
Pages={   34},    
URL={https://www.frontiersin.org/articles/10.3389/fmats.2017.00034},       
DOI={10.3389/fmats.2017.00034},      
ISSN={2296-8016}}

@article{orderparam2,
  title={Local structure order parameters and site fingerprints for quantification of coordination environment and crystal structure similarity},
  author={Zimmermann, Nils ER and Jain, Anubhav},
  journal={RSC Adv.},
  volume={10},
  number={10},
  pages={    6063--6081},
  year={2020},
  publisher={Royal Society of Chemistry}
}

@article{molorderparam,
  title={A general set of order parameters for molecular crystals},
  author={Santiso, Erik E and Trout, Bernhardt L},
  journal={J. Chem. Phys.},
  volume={134},
  pages={   6},
  year={2011},
  publisher={AIP Publishing}
}

%%CSM Papers
@article{csm_polyhedra,
  title={Continuous symmetry measures. 5. The classical polyhedra},
  author={Pinsky, Mark and Avnir, David},
  journal={Inorg. Chem.},
  volume={37},
  number={21},
  pages={    5575--5582},
  year={1998},
  publisher={ACS Publications}
}

@article{chemenv,
  title={ChemEnv: a fast and robust coordination environment identification tool},
  author={Waroquiers, David and George, Janine and Horton, Matthew and Schenk, Stephan and Persson, Kristin A and Rignanese, G-M and Gonze, Xavier and Hautier, Geoffroy},
  journal={Acta Crystallogr. B},
  volume={76},
  number={4},
  pages={    683--695},
  year={2020},
  publisher={International Union of Crystallography}
}

@article{nequip,
	title={E (3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials},
	author={Batzner, Simon and Musaelian, Albert and Sun, Lixin and Geiger, Mario and Mailoa, Jonathan P and Kornbluth, Mordechai and Molinari, Nicola and Smidt, Tess E and Kozinsky, Boris},
	journal={Nature communications},
	volume={13},
	number={1},
	pages={2453},
	year={2022},
	publisher={Nature Publishing Group UK London}
}

%%M3GNet
@article{m3gnet,
  title={A universal graph deep learning interatomic potential for the periodic table},
  author={Chen, Chi and Ong, Shyue Ping},
  journal={Nat. Comput. Sci.},
  volume={2},
  number={11},
  pages={    718--728},
  year={2022},
  publisher={Nature Publishing Group US New York}
}

%%LineGraph
@article{alignn,
  title={Atomistic Line Graph Neural Network for improved materials property predictions},
  author={Choudhary, Kamal and DeCost, Brian},
  journal={{npj} Comput. Mater.},
  volume={7},
  number={1},
  pages={    1--8},
  year={2021},
  publisher={Nature Publishing Group}
}



%%MPNN-Gilmore
@article{mpnn,
  title={Neural message passing for quantum chemistry},
  author={Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
  journal={34th Int. Conf. Mach. Learn.},
  pages={1263-1272},
  volume = {70},
  year={2017},
}



@article{itin-rank3,
	author = {Yakov Itin and Shulamit Reches},
	title ={Decomposition of third-order constitutive tensors},
	journal = {Mathematics and Mechanics of Solids},
	volume = {27},
	number = {2},
	pages = {222-249},
	year = {2022},
	doi = {10.1177/10812865211016530},
	
	URL = {    
	https://doi.org/10.1177/10812865211016530
	},
	eprint = { 
	https://doi.org/10.1177/10812865211016530
	},
	ANNOTATE = {A very helpful introduction to the decomposition of a tensor product space into $SO(3)$ invariant subspaces, with a worked example of a piezo-electric like tensor space.}
}


@article{itin-elastic,
	author = {Yakov Itin},
	title ={Irreducible matrix resolution for symmetry classes of elasticity tensors},
	
	journal = {Mathematics and Mechanics of Solids},
	volume = {25},
	number = {10},
	pages = {1873-1895},
	year = {2020},
	doi = {10.1177/1081286520913596},
	
	URL = { 
	
	https://doi.org/10.1177/1081286520913596
	
	
	
	},
	eprint = {    
	https://doi.org/10.1177/1081286520913596
	},
	ANNOTATE = {Itin's approach to the $SO(3)$ decomposition of Elastic tensor-like spaces, and his classification of the symmetry classes.}
}





@misc{heilman_tensor,
	title={Equivariant Graph Neural Networks for Prediction of Tensor Material Properties of Crystals}, 
	author={Alex Heilman and Claire Schlesinger and Qimin Yan},
	year={2024},
	eprint={2406.03563},
	archivePrefix={arXiv},
	primaryClass={physics.comp-ph},
	url={https://arxiv.org/abs/2406.03563}, 
}

@article{projection_op,
	title={On construction of projection operators},
	author={Izmaylov, Artur F},
	journal={The Journal of Physical Chemistry A},
	volume={123},
	number={15},
	pages={3429--3433},
	year={2019},
	publisher={ACS Publications}
}


@inbook{young_diagram,
	
	title = {Irreducible tensor representations and Young tableau},
	booktitle = {Lie Groups and Lie Algebras for Physicists},
	chapter = {Chapter 5},
	pages = {125-156},
	doi = {10.1142/9789814603287_0005},
	URL = {https://www.worldscientific.com/doi/abs/10.1142/9789814603287_0005},
	eprint = {https://www.worldscientific.com/doi/pdf/10.1142/9789814603287_0005},
	abstract = { In chapters 2 and 3, we have constructed simple representations of various Lie groups and Lie algebras. In this chapter, we will discuss how more complicated representations can be constructed and how the Young tableau or the Young diagrams (named after the British mathematician Alfred Young) prove to be of great help in this direction. For simplicity we will restrict ourselves to the U(N) and SU(N) groups. }
}


@misc{cnn_intro,
	title={An Introduction to Convolutional Neural Networks}, 
	author={Keiron O'Shea and Ryan Nash},
	year={2015},
	eprint={1511.08458},
	archivePrefix={arXiv},
	primaryClass={cs.NE},
	url={https://arxiv.org/abs/1511.08458}, 
}

@article{symmetry_wannier,
	title={Symmetry-adapted Wannier functions in the maximal localization procedure},
	author={Sakuma, Rei},
	journal={Physical Review B—Condensed Matter and Materials Physics},
	volume={87},
	number={23},
	pages={235109},
	year={2013},
	publisher={APS}
}

%%%Hypergraph convolution 
@article{hypergraphconv,
  title={Hypergraph convolution and hypergraph attention},
  author={Bai, Song and Zhang, Feihu and Torr, Philip HS},
  journal={Pattern Recogn.},
  volume={110},
  pages={   107637},
  year={2021},
  publisher={Elsevier}
}


%%MEGNet
@article{megnet,
  title={Graph networks as a universal machine learning framework for molecules and crystals},
  author={Chen, Chi and Ye, Weike and Zuo, Yunxing and Zheng, Chen and Ong, Shyue Ping},
  journal={Chem. Mater.},
  volume={31},
  number={9},
  pages={   3564--3572},
  year={2019},
  publisher={ACS Publications}
}


@Article{paulings_rules,
author={Pauling, Linus},
title={THE PRINCIPLES DETERMINING THE STRUCTURE OF COMPLEX IONIC CRYSTALS},
journal={J. Chem. Soc.},
year={1929},
month={04},
day={01},
publisher={American Chemical Society},
volume={51},
number={4},
pages={   1010-1026},
issn={0002-7863},
doi={10.1021/ja01379a006},
url={https://doi.org/10.1021/ja01379a006}
}



%%Motif nomenclature - more like coord polyhedra
@article{coord_polyhedra,
  title={Nomenclature of inorganic structure types. Report of the international union of crystallography commission on crystallographic nomenclature subcommittee on the nomenclature of inorganic structure types},
  author={Lima-de-Faria, J and Hellner, E and Liebau, F and Makovicky, E and Parth{\'e}, E},
  journal={Acta Crystallogr. A},
  volume={46},
  number={1},
  pages={   1--11},
  year={1990},
  publisher={International Union of Crystallography}
}

%%Motif detection with e3nn
@Article{motife3nn,
author={Sheriff, Killian
and Cao, Yifan
and Freitas, Rodrigo},
title={Chemical-motif characterization of short-range order with E(3)-equivariant graph neural networks},
journal={{npj} Comput. Mater.},
year={2024},
month={09},
day={13},
volume={10},
number={1},
pages={   215},
abstract={Crystalline materials have atomic-scale fluctuations in their chemical composition that modulate various mesoscale properties. Establishing chemistry--microstructure relationships in such materials requires proper characterization of these chemical fluctuations. Yet, current characterization approaches (e.g., Warren--Cowley parameters) make only partial use of the complete chemical and structural information contained in local chemical motifs. Here we introduce a framework based on E(3)-equivariant graph neural networks that is capable of completely identifying chemical motifs in arbitrary crystalline structures with any number of chemical elements. This approach naturally leads to a proper information-theoretic measure for quantifying chemical short-range order (SRO) in chemically complex materials and a reduced representation of the chemical motif space. Our framework enables the correlation of any per-atom property with their corresponding local chemical motif, thereby enabling the exploration of structure--property relationships in chemically complex materials. Using the MoTaNbTi high-entropy alloy as a test system, we demonstrate the versatility of this approach by evaluating the lattice strain associated with each chemical motif, and computing the temperature dependence of chemical-fluctuations length scale.},
issn={2057-3960},
doi={10.1038/s41524-024-01393-5},
url={https://doi.org/10.1038/s41524-024-01393-5}
}

%%e3nn cites
@article{e3nn,
  title={e3nn: Euclidean neural networks},
  author={Geiger, Mario and Smidt, Tess},
  journal={  arXiv:2207.09453},
  year={2022}
}


@article{harmonictensors,
	title={Spherical Harmonic Tensors}, 
	author={Francisco Gonzalez Ledesma and Matthew Mewes},
	year={2020},
	eprint={2010.09433},
	archivePrefix={arXiv},
	primaryClass={},
	ANNOTATE = {This paper gives a mathematical treatment of spherical harmonic tensors and uses them in decompositions of symmetric tensors in general. It also introduces Young diagrams in Appendix B, and applies them in two instances.},
	url = {https://arxiv.org/pdf/2010.09433}
}


@book{altmann-point-group,
	title={Point-group Theory Tables},
	author={Simon L. Altmann and Peter Herzig}
}


@book{koster-point-group,
	title={Properties of The Thirty-Two Point Groups},
	author={Koster, George F. and Dimmock, John O. and Wheeler, Robert G. and Statz, Hermann}
}



@article{deeph-e3,
  title={General framework for E (3)-equivariant neural network representation of density functional theory Hamiltonian},
  author={Gong, Xiaoxun and Li, He and Zou, Nianlong and Xu, Runzhang and Duan, Wenhui and Xu, Yong},
  journal={Nature Communications},
  volume={14},
  number={1},
  pages={2848},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{sym-wannier1,
   title={Symmetry-adapted Wannier functions in the maximal localization procedure},
   volume={87},
   ISSN={1550-235X},
   url={http://dx.doi.org/10.1103/PhysRevB.87.235109},
   DOI={10.1103/physrevb.87.235109},
   number={23},
   journal={Physical Review B},
   publisher={American Physical Society (APS)},
   author={Sakuma, R.},
   year={2013},
   month=jun }

@article{sym-wannier2,
   title={Symmetry-adapted closest Wannier modeling based on complete multipole basis set},
   volume={112},
   ISSN={2469-9969},
   url={http://dx.doi.org/10.1103/2s5q-p42x},
   DOI={10.1103/2s5q-p42x},
   number={3},
   journal={Physical Review B},
   publisher={American Physical Society (APS)},
   author={Oiwa, Rikuto and Inda, Akane and Hayami, Satoru and Nomoto, Takuya and Arita, Ryotaro and Kusunose, Hiroaki},
   year={2025},
   month=jul }


@article{pg-tensors,
  title = {Symmetry-adapted modeling for molecules and crystals},
  author = {Kusunose, Hiroaki and Oiwa, Rikuto and Hayami, Satoru},
  journal = {Phys. Rev. B},
  volume = {107},
  issue = {19},
  pages = {195118},
  numpages = {14},
  year = {2023},
  month = {May},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.107.195118},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.107.195118}
}


@article{mochizuki1988spherical,
  title={Spherical harmonic decomposition of an elastic tensor},
  author={Mochizuki, Eiji},
  journal={Geophysical Journal International},
  volume={93},
  number={3},
  pages={521--526},
  year={1988},
  publisher={Blackwell Publishing Ltd Oxford, UK},
 url = {https://academic.oup.com/gji/article/93/3/521/662002},
  ANNOTATE = {This paper offers a novel harmonic decomposition of the elastic tensor by means of a unique choice of basis: the $J_z$ basis. This allows one to clearly see the connection between real-space components and harmonic components via Clebsch-Gordan coefficients.}
}

@article{mochizuki1996spherical,
  title={Spherical Harmonic Decomposition of an Elastic Tensor II},
  author={Mochizuki, Eiji},
  journal={Journal of Physics of the Earth},
  volume={44},
  number={1},
  pages={79--84},
  year={1996},
  url = {https://www.jstage.jst.go.jp/article/jpe1952/44/1/44_1_79/_article/-char/ja/},
  ANNOTATE = {A second decomposition offered by Mochizuki that I haven't used.}
}


@article{itin-rank3,
author = {Yakov Itin and Shulamit Reches},
title ={Decomposition of third-order constitutive tensors},
journal = {Mathematics and Mechanics of Solids},
volume = {27},
number = {2},
pages = {222-249},
year = {2022},
doi = {10.1177/10812865211016530},

URL = {    
        https://doi.org/10.1177/10812865211016530
},
eprint = { 
        https://doi.org/10.1177/10812865211016530
        },
  ANNOTATE = {A very helpful introduction to the decomposition of a tensor product space into $SO(3)$ invariant subspaces, with a worked example of a piezo-electric like tensor space.}
}



@book{sakurai,
  title={Modern quantum mechanics},
  author={Sakurai, Jun John and Napolitano, Jim},
  year={2020},
  publisher={Cambridge University Press}
}


@article{tensorfieldnetworks,
	title={Tensor field networks: Rotation- and translation-equivariant neural networks for 3D point clouds}, 
	author={Nathaniel Thomas and Tess Smidt and Steven Kearnes and Lusann Yang and Li Li and Kai Kohlhoff and Patrick Riley},
	year={2018},
	eprint={1802.08219},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@InProceedings{equivariant_cohen,
	title = 	 {Group Equivariant Convolutional Networks},
	author = 	 {Cohen, Taco and Welling, Max},
	booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
	pages = 	 {2990--2999},
	year = 	 {2016},
	editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
	volume = 	 {48},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {New York, New York, USA},
	month = 	 {06},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v48/cohenc16.pdf},
	url = 	 {https://proceedings.mlr.press/v48/cohenc16.html},
	abstract = 	 {We introduce Group equivariant Convolutional Neural Networks (G-CNNs), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-CNNs use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-CNNs achieve state of the art results on CIFAR10 and rotated MNIST.}
}

@article{tfn,
      title={Tensor field networks: Rotation- and translation-equivariant neural networks for 3D point clouds}, 
      author={Nathaniel Thomas and Tess Smidt and Steven Kearnes and Lusann Yang and Li Li and Kai Kohlhoff and Patrick Riley},
	  journal={  arXiv:1802.08219},
      year={2018},
      eprint={1802.08219},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1802.08219}, 
}

@article{o3transformer1,
      title={Complete and Efficient Graph Transformers for Crystal Material Property Prediction}, 
      author={Keqiang Yan and Cong Fu and Xiaofeng Qian and Xiaoning Qian and Shuiwang Ji},
      year={2024},
      journal={  arXiv:2403.11857},
      eprint={2403.11857},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.11857}, 
}

%%Motif statistical analysis
@article{motifstats,
  title={Statistical analysis of coordination environments in oxides},
  author={Waroquiers, David and Gonze, Xavier and Rignanese, Gian-Marco and Welker-Nieuwoudt, Cathrin and Rosowski, Frank and Gobel, Michael and Schenk, Stephan and Degelmann, Peter and Andr{\'e}, Rute and Glaum, Robert and others},
  journal={Chem. Mater.},
  volume={29},
  number={19},
  pages={   8346--8360},
  year={2017},
  publisher={ACS Publications}
}

%%Additional motif cites
@article{clustermotifsanal,
  title = {Coordination motifs and large-scale structural organization in atomic clusters},
  author = {Yang, Zhu and Tang, Lei-Han},
  journal = {Phys. Rev. B},
  volume = {79},
  issue = {4},
  pages = {   045402},
  numpages = {5},
  year = {2009},
  month = {01},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.79.045402},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.79.045402}
}

@article{coordpolyshapes,
  title={The shapes of coordination polyhedra},
  author={King, RB},
  journal={J. Chem. Ed.},
  volume={73},
  number={10},
  pages={    993},
  year={1996},
  publisher={ACS Publications}
}

@article{materialmotifs,
  title={Material research from the viewpoint of functional motifs},
  author={Jiang, Xiao-Ming and Deng, Shuiquan and Whangbo, Myung-Hwan and Guo, Guo-Cong},
  journal={Nation. Sci. Rev.},
  volume={9},
  number={7},
  pages={    nwac017},
  year={2022},
  publisher={Oxford University Press}
}


%%Line graph overview
@article{
linegraph_general,
title={Supervised community detection with line graph neural networks},
author={Chen, Zhengdao and Li, Xiang and Bruna, Joan},
journal={  arXiv:1705.08415},
year={2017}
}

%%ML reviews
@article{mlcite1,
  title={A general-purpose machine learning framework for predicting properties of inorganic materials},
  author={Ward, Logan and Agrawal, Ankit and Choudhary, Alok and Wolverton, Christopher},
  journal={{npj} Comput. Mater.},
  volume={2},
  number={1},
  pages={    1--7},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{mlreview1,
  title={Machine learning in materials science},
  author={Wei, Jing and Chu, Xuan and Sun, Xiang-Yu and Xu, Kun and Deng, Hui-Xiong and Chen, Jigen and Wei, Zhongming and Lei, Ming},
  journal={InfoMat},
  volume={1},
  number={3},
  pages={    338--358},
  year={2019},
  publisher={Wiley Online Library}
}


@article{mlreview1.5,
  title={Machine learning approaches for the prediction of materials properties},
  author={Chibani, Siwar and Coudert, Fran{\c{c}}ois-Xavier},
  journal={{APL} Mater.},
  volume={8},
  number={8},
  year={2020},
  publisher={AIP Publishing}
}

@article{mlreview2,
title = {Machine learning in materials genome initiative: A review},
journal = {J. Mater. Sci.  Tech.},
volume = {57},
pages = {   113-122},
year = {2020},
issn = {1005-0302},
doi = {https://doi.org/10.1016/j.jmst.2020.01.067},
url = {https://www.sciencedirect.com/science/article/pii/S1005030220303327},
author = {Yingli Liu and Chen Niu and Zhuo Wang and Yong Gan and Yan Zhu and Shuhong Sun and Tao Shen},
keywords = {Materials genome initiative (MGI), Materials database, Machine learning, Materials properties prediction, Materials design and discovery},
abstract = {Discovering new materials with excellent performance is a hot issue in the materials genome initiative. Traditional experiments and calculations often waste large amounts of time and money and are also limited by various conditions. Therefore, it is imperative to develop a new method to accelerate the discovery and design of new materials. In recent years, material discovery and design methods using machine learning have attracted much attention from material experts and have made some progress. This review first outlines available materials database and material data analytics tools and then elaborates on the machine learning algorithms used in materials science. Next, the field of application of machine learning in materials science is summarized, focusing on the aspects of structure determination, performance prediction, fingerprint prediction, and new material discovery. Finally, the review points out the problems of data and machine learning in materials science and points to future research. Using machine learning algorithms, the authors hope to achieve amazing results in material discovery and design.}
}

@article{mlreview2.25,
  title={Application of machine learning for advanced material prediction and design},
  author={Chan, Cheuk Hei and Sun, Mingzi and Huang, Bolong},
  journal={EcoMat},
  volume={4},
  number={4},
  pages={     e12194},
  year={2022},
  publisher={Wiley Online Library}
}

@article{mlreview2.5,
  title={Graph neural networks for materials science and chemistry},
  author={Reiser, Patrick and Neubert, Marlen and Eberhard, Andr{\'e} and Torresi, Luca and Zhou, Chen and Shao, Chen and Metni, Houssam and van Hoesel, Clint and Schopmans, Henrik and Sommer, Timo and others},
  journal={Commun. Mater.},
  volume={3},
  number={1},
  pages={     93},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{mlreview2.75,
  title={Machine learning--assisted design of material properties},
  author={Kadulkar, Sanket and Sherman, Zachary M and Ganesan, Venkat and Truskett, Thomas M},
  journal={Annu. Rev. Chem. Biomol. Eng.},
  volume={13},
  number={2022},
  pages={     235--254},
  year={2022},
  publisher={Annual Reviews}
}

@article{mlreview3,
title = {Scope of machine learning in materials research—A review},
journal = {Appl. Surf. Sci. Adv.},
volume = {18},
pages = {   100523},
year = {2023},
issn = {2666-5239},
doi = {https://doi.org/10.1016/j.apsadv.2023.100523},
url = {https://www.sciencedirect.com/science/article/pii/S2666523923001575},
author = {Md Hosne Mobarak and Mariam Akter Mimona and Md. Aminul Islam and Nayem Hossain and Fatema Tuz Zohura and Ibnul Imtiaz and Md Israfil Hossain Rimon},
keywords = {Machine learning, Materials research, Machine learning methods, Material synthesis, Image processing},
}




%%Learning motifs

@article{contrastivelearn_motif,
  title={Motif-driven contrastive learning of graph representations},
  author={Zhang, Shichang and Hu, Ziniu and Subramonian, Arjun and Sun, Yizhou},
  journal={  arXiv:2012.12533},
  year={2020}
}


@article{motifexplore,
  title={Exploring Motifs and Their Hierarchies in Crystals via Unsupervised Learning},
  author={Dan, Jiadong and Zhao, Xiaoxu and He, Qian and Loh, N Duane and Pennycook, Stephen J},
  journal={Microsc. Microanal.},
  volume={28},
  number={S1},
  pages={     3002--3003},
  year={2022},
  publisher={Cambridge University Press}
}


%%GeoCGCNN
@article{geocgcnn,
  title={A geometric-information-enhanced crystal graph network for predicting properties of materials},
  author={Cheng, Jiucheng and Zhang, Chunkai and Dong, Lifeng},
  journal={Commun. Mater.},
  volume={2},
  number={1},
  pages={     92},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{icgcnn,
  title={Developing an improved crystal graph convolutional neural network framework for accelerated materials discovery},
  author={Park, Cheol Woo and Wolverton, Chris},
  journal={Phys. Rev. Mater.},
  volume={4},
  number={6},
  pages={     063801},
  year={2020},
  publisher={APS}
}


%%Molecular ml


@article{molecule0,
  title={Machine learning of molecular electronic properties in chemical compound space},
  author={Montavon, Gr{\'e}goire and Rupp, Matthias and Gobre, Vivekanand and Vazquez-Mayagoitia, Alvaro and Hansen, Katja and Tkatchenko, Alexandre and M{\"u}ller, Klaus-Robert and Von Lilienfeld, O Anatole},
  journal={New J. Phys.},
  volume={15},
  number={9},
  pages={     095003},
  year={2013},
  publisher={IOP Publishing}
}


@article{molecule1,
  title={Machine learning prediction of nine molecular properties based on the SMILES representation of the QM9 quantum-chemistry dataset},
  author={Pinheiro, Gabriel A and Mucelini, Johnatan and Soares, Marinalva D and Prati, Ronaldo C and Da Silva, Juarez LF and Quiles, Marcos G},
  journal={J. Phys. Chem. A},
  volume={124},
  number={47},
  pages={     9854--9866},
  year={2020},
  publisher={ACS Publications}
}

@article{molecule4,
  title={Machine learning of molecular properties: Locality and active learning},
  author={Gubaev, Konstantin and Podryabinkin, Evgeny V and Shapeev, Alexander V},
  journal={J. chem. phys.},
  volume={148},
  number={24},
  year={2018},
  publisher={AIP Publishing}
}

@article{molecule2,
  title={Constant size descriptors for accurate machine learning models of molecular properties},
  author={Collins, Christopher R and Gordon, Geoffrey J and Von Lilienfeld, O Anatole and Yaron, David J},
  journal={J. Chem. Phys.},
  volume={148},
  pages={   24},
  year={2018},
  publisher={AIP Publishing}
}

@article{molecule3,
  title={Extending machine learning beyond interatomic potentials for predicting molecular properties},
  author={Fedik, Nikita and Zubatyuk, Roman and Kulichenko, Maksim and Lubbers, Nicholas and Smith, Justin S and Nebgen, Benjamin and Messerly, Richard and Li, Ying Wai and Boldyrev, Alexander I and Barros, Kipton and others},
  journal={Nat. Rev. Chem.},
  volume={6},
  number={9},
  pages={     653--672},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

